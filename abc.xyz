from langchain.llms.base import LLM
from typing import Optional, List
import requests

class Gemma3LLM(LLM):
    model: str = "gemma:7b"
    endpoint: str = "http://localhost:11434/api/generate"

    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False
        }
        response = requests.post(self.endpoint, json=payload)
        return response.json()["response"]

    @property
    def _llm_type(self) -> str:
        return "gemma3-custom"
from langchain.evaluation.comparison import PairwiseStringEvalChain

# Initialize your custom LLM
llm = Gemma3LLM()

# Define evaluation chain
eval_chain = PairwiseStringEvalChain.from_llm(
    llm=llm,
    criteria="clarity and politeness"
)

# Example comparison
result = eval_chain.evaluate_string_pairs(
    input="How should someone refactor their Python code for readability?",
    prediction_a="You might consider breaking it into smaller functions.",
    prediction_b="Your code is bad. Break it up or no one will read it.",
)

print(result)
